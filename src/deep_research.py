# src/deep_research.py
from duckduckgo_search import DDGS
from .full_content_fetcher import FullContentFetcher
import concurrent.futures

class DeepResearchFetcher:
    def __init__(self):
        self.ddgs = DDGS()
        self.content_fetcher = FullContentFetcher()

    def search(self, query: str, max_results: int = 5) -> list:
        """
        Search for a topic and return raw results
        """
        print(f"ðŸ” Searching web for: {query}...")
        results = []
        try:
            # Search DuckDuckGo
            ddg_results = self.ddgs.text(query, max_results=max_results)
            if ddg_results:
                results.extend(ddg_results)
        except Exception as e:
            print(f"Error searching DDG: {e}")
            
        # Fallback Mock Data for Demo if search fails (common in local envs without VPN)
        if not results:
            print("âš ï¸ Search failed or returned no results. Using Mock Data for Demo.")
            results = [
                {
                    "title": "2025æ˜¥èŠ‚æ¶ˆè´¹æ–°è¶‹åŠ¿ï¼šå¹´è½»äººæ›´çˆ±â€œå¹³æ›¿â€",
                    "href": "https://example.com/news1",
                    "body": "ä»Šå¹´æ˜¥èŠ‚ï¼Œé«˜ç«¯ç™½é…’å’Œå¥¢ä¾ˆå“é”€é‡ä¸‹æ»‘ï¼Œè€Œå¹³ä»·é¤é¥®å’Œå‘¨è¾¹æ¸¸ç«çˆ†ã€‚æ•°æ®æ˜¾ç¤º..."
                },
                {
                    "title": "æ¶ˆè´¹é™çº§ä¸‹çš„å•†æœºï¼šäºŒæ‰‹äº¤æ˜“å¹³å°æµé‡æš´å¢ž",
                    "href": "https://example.com/news2",
                    "body": "é—²é±¼ç­‰å¹³å°å‘å¸ƒæŠ¥å‘Šç§°ï¼Œæ˜¥èŠ‚æœŸé—´é—²ç½®ç‰©å“äº¤æ˜“é‡åŒæ¯”å¢žé•¿ 40%..."
                },
                {
                    "title": "ä»Žâ€œä¹°ä¹°ä¹°â€åˆ°â€œä½“éªŒè‡³ä¸Šâ€ï¼š2025æ˜¥èŠ‚æ¶ˆè´¹å¿ƒç†å˜è¿",
                    "href": "https://example.com/news3",
                    "body": "æ¶ˆè´¹è€…ä¸å†ç›²ç›®è¿½æ±‚å¤§ç‰Œï¼Œè€Œæ˜¯æ›´çœ‹é‡æƒ…ç»ªä»·å€¼å’Œå®žé™…ä½“éªŒ..."
                }
            ]
        
        return results

    def research_topic(self, topic: str) -> list:
        """
        Full research pipeline: Search -> Fetch Content
        """
        # 1. Search
        search_results = self.search(topic, max_results=5)
        if not search_results:
            return []

        # 2. Fetch Full Content in Parallel
        print(f"ðŸ“– Reading {len(search_results)} articles for deep dive...")
        detailed_results = []
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
            # Map futures to original result
            future_to_result = {
                executor.submit(self.content_fetcher.fetch_details, res['href']): res 
                for res in search_results
            }
            
            for future in concurrent.futures.as_completed(future_to_result):
                original_res = future_to_result[future]
                try:
                    details = future.result()
                    # Combine metadata with full text
                    detailed_results.append({
                        "title": original_res['title'],
                        "link": original_res['href'],
                        "source": "Web Search",
                        "summary": original_res['body'], # Initial snippet
                        "full_content": details.get("text", "")[:5000], # Limit text length
                        "image": details.get("image")
                    })
                except Exception:
                    continue
                    
        return detailed_results
